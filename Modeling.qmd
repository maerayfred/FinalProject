---
title: "Modeling"
format: html
editor: visual
---

## Libraries

```{r}
library(tidymodels)
library(tidyverse)
library(rpart)
library(baguette)
library(parsnip)
library(tidyr)
library(dplyr)
library(readr)
library(lubridate)
library(psych)
library(tidymodels)
library(stats)
library(rsample)
library(yardstick)
library(tidyverse)
library(corrr)
library(parsnip)
library(tune)
library(glmnet)
library(baguette)
library(ranger)
library(rpart.plot)
library(caret)
```


## Setting up Data

```{r}

data<-read.csv("diabetes_binary_health_indicators_BRFSS2015.csv")

data<- data|>
  mutate(HighBP=factor(HighBP, levels=c(0,1),labels=c("Normal_BP","High_BP")),
         HighChol=factor(HighChol, levels=c(0,1),labels=c("Normal_Chol","High_Chol")),
         CholCheck=as.factor(CholCheck),
         Smoker=factor(Smoker,levels=c(0,1),labels=c("Non_Smoker","Smoker")),
         Stroke=factor(Stroke, levels=c(0,1),labels=c("No_Stroke","Yes_Stroke")),
         Fruits=factor(Fruits,levels=c(0,1),labels=c("No_Fruits","Eats_Fruits")),
         Veggies=factor(Veggies,levels=c(0,1),labels=c("No_Veggies","Eats_Veggies")),
         Sex=factor(Sex, level=c(0,1), labels = c("Female","Male")),
         GenHlth=factor(GenHlth,levels=c(1,2,3,4,5), 
                        labels=c("Excellent","Very_Good","Good","Fair","Poor")),
         Age=factor(Age, levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),
                    labels=c("18-24","25-29","30-34","35-39","40-44","45-49","50-54","55-59",
                            "60-64","65-69","70-74","75-79","80+" )),
         Education=factor(Education,levels=c(1,2,3,4,5,6),labels=c("None-K","Grades 1-8",
                                                                   "Grades 9-11","HS Diploma","Some College","Bachelor's Degree or Higher")),
         Income=factor(Income,levels=c(1,2,3,4,5,6,7,8),labels=c("<10K","<15K",
          "<20K","<25K","<35K","<50K",
          "<75K",">=75K")),
         Diabetes_binary=factor(Diabetes_binary,levels=c(0,1),labels=c("Not_Diabetic","Diabetic")),
         HeartDiseaseorAttack=factor(HeartDiseaseorAttack,levels=c(0,1),labels=c("No_Heart Disease","Heart_Disease")),
         PhysActivity=factor(PhysActivity,levels=c(0,1),labels=c("No_Physical Activity","Physical_Activity")),
         HvyAlcoholConsump=factor(HvyAlcoholConsump,levels=c(0,1),labels=c("Not_Heavy Drinker","Heavy_Drinker")),
         AnyHealthcare=factor(AnyHealthcare,levels=c(0,1),labels=c("No_Health_Coverage","Yes_Health_Coverage")),
         NoDocbcCost=factor(NoDocbcCost,levels=c(0,1),labels=c("Cost_Issue","Cost_Not_Issue")),
         DiffWalk=factor(DiffWalk,levels=c(0,1),labels=c("No_Difficulty_Walking","Difficulty_Walking"))
         )


set.seed(1234)

split_data<-initial_split(data,prop=0.7,strata = Diabetes_binary)
train_data<-training(split_data)
test_data<-testing(split_data)
cv_fold_data<-vfold_cv(train_data,v=5,strata=Diabetes_binary)
```


## Random Forest Model

```{r}
data2<-data|>
  select(Sex,Veggies,AnyHealthcare,GenHlth,PhysActivity)


rec1<-recipe(Diabetes_binary~Sex+Veggies+AnyHealthcare+GenHlth+PhysActivity,data=train_data)|>
   step_dummy(Sex,Veggies,GenHlth,AnyHealthcare,PhysActivity)



rf_spec<-rand_forest(mtry=tune(),trees = 100)|>
  set_engine("ranger", importance = "impurity")|>
  set_mode("classification")

rf_wkf<-workflow()|>
  add_recipe(rec1)|>
  add_model(rf_spec)

mtry_vals <- grid_regular(mtry(range = c(1, ncol(data2) - 1)), levels = 5)

rf_fit<-rf_wkf|>
  tune_grid(resamples=cv_fold_data,
            grid=mtry_vals,
            metrics=metric_set(mn_log_loss))

rf_fit|>
  collect_metrics()|>
  filter(.metric=="mn_log_loss")|>
  arrange(mean)


rf_best_params<-select_best(rf_fit,metric = "mn_log_loss")
rf_best_params


rf_final_wkf<-rf_wkf|>
  finalize_workflow(rf_best_params)

rf_final_fit<-rf_final_wkf|>
  last_fit(split_data,metrics=metric_set(mn_log_loss))

rf_final_fit|>collect_metrics()

rf_model <- extract_fit_parsnip(rf_final_fit)
importance <- ranger::importance(rf_model$fit)
coef_table <- tibble(
  variable = names(importance),
  importance = importance)|>
  arrange(desc(importance))
print(coef_table)


```



## Classification Tree
```{r}
tree_mod<-decision_tree(tree_depth = tune(),
                        min_n = 5,
                        cost_complexity = tune()
                        )|>
  set_engine("rpart")|>
  set_mode("classification")

tree_wkf<-workflow()|>
  add_recipe(rec1)|>
  add_model(tree_mod)

temp<-tree_wkf|>
  tune_grid(resamples = cv_fold_data,metrics = metric_set(mn_log_loss))
  temp|>
    collect_metrics()

  
  
  tree_grid<-grid_regular(cost_complexity(),
                          tree_depth(),
                          levels=c(5,5))
  tree_fits<-tree_wkf|>
    tune_grid(resamples=cv_fold_data,metrics=metric_set(mn_log_loss),
              grid=tree_grid)
  
  tree_fits
  
  tree_fits|>
    collect_metrics()|>
    filter(.metric=="mn_log_loss")|>
    arrange(mean)

  
tree_best_params<-select_best(tree_fits, metric="mn_log_loss")
tree_best_params

tree_final_wkf<-tree_wkf|>
  finalize_workflow(tree_best_params)

tree_final_fit<-tree_final_wkf|>
  last_fit(split_data,metrics=metric_set(mn_log_loss))
tree_final_fit

tree_final_fit|>
  collect_metrics()

tree_final_model<-extract_workflow(tree_final_fit)
tree_final_model

tree_final_model %>%
  extract_fit_engine () %>%
  rpart.plot::rpart.plot(roundint=FALSE)



```
## Final and Best Model

```{r}
best<-rf_wkf|>
  finalize_workflow(rf_best_params)|>
  fit(train_data)
best

predictions <- predict(best, data)

  class_table <- table(predictions)
  
  class_table

  prevalent_class <- names(which.max(class_table))
  
  # Return the result as a JSON response
  list(predicted_class = prevalent_class)
```



