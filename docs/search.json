[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyr)\n\ndata&lt;-read.csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\ndata&lt;- data|&gt;\n  mutate(HighBP=factor(HighBP, levels=c(0,1),labels=c(\"Normal_BP\",\"High_BP\")),\n         HighChol=factor(HighChol, levels=c(0,1),labels=c(\"Normal_Chol\",\"High_Chol\")),\n         CholCheck=as.factor(CholCheck),\n         Smoker=factor(Smoker,levels=c(0,1),labels=c(\"Non_Smoker\",\"Smoker\")),\n         Stroke=factor(Stroke, levels=c(0,1),labels=c(\"No_Stroke\",\"Yes_Stroke\")),\n         Fruits=factor(Fruits,levels=c(0,1),labels=c(\"No_Fruits\",\"Eats_Fruits\")),\n         Veggies=factor(Veggies,levels=c(0,1),labels=c(\"No_Veggies\",\"Eats_Veggies\")),\n         Sex=factor(Sex, level=c(0,1), labels = c(\"Female\",\"Male\")),\n         GenHlth=factor(GenHlth,levels=c(1,2,3,4,5), \n                        labels=c(\"Excellent\",\"Very Good\",\"Good\",\"Fair\",\"Poor\")),\n         Age=factor(Age, levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),\n                    labels=c(\"18-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"45-49\",\"50-54\",\"55-59\",\n                            \"60-64\",\"65-69\",\"70-74\",\"75-79\",\"80+\" )),\n         Education=factor(Education,levels=c(1,2,3,4,5,6),labels=c(\"None-K\",\"Grades 1-8\",\n                                                                   \"Grades 9-11\",\"HS Diploma\",\"Some College\",\"Bachelor's Degree or Higher\")),\n         Income=factor(Income,levels=c(1,2,3,4,5,6,7,8),labels=c(\"&lt;10K\",\"&lt;15K\",\n          \"&lt;20K\",\"&lt;25K\",\"&lt;35K\",\"&lt;50K\",\n          \"&lt;75K\",\"&gt;=75K\")),\n         Diabetes_binary=factor(Diabetes_binary,levels=c(0,1),labels=c(\"Not_Diabetic\",\"Diabetic\")),\n         HeartDiseaseorAttack=factor(HeartDiseaseorAttack,levels=c(0,1),labels=c(\"No_Heart Disease\",\"Heart_Disease\")),\n         PhysActivity=factor(PhysActivity,levels=c(0,1),labels=c(\"No_Physical Activity\",\"Physical_Activity\")),\n         HvyAlcoholConsump=factor(HvyAlcoholConsump,levels=c(0,1),labels=c(\"Not_Heavy Drinker\",\"Heavy_Drinker\")),\n         AnyHealthcare=factor(AnyHealthcare,levels=c(0,1),labels=c(\"No_Health_Coverage\",\"Yes_Health_Coverage\")),\n         NoDocbcCost=factor(NoDocbcCost,levels=c(0,1),labels=c(\"Cost_Issue\",\"Cost_Not_Issue\")),\n         DiffWalk=factor(DiffWalk,levels=c(0,1),labels=c(\"No_Difficulty_Walking\",\"Difficulty_Walking\"))\n         )\n\nstr(data)\n\n'data.frame':   253680 obs. of  22 variables:\n $ Diabetes_binary     : Factor w/ 2 levels \"Not_Diabetic\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"Normal_BP\",\"High_BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"Normal_Chol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num  40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"Non_Smoker\",\"Smoker\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No_Stroke\",\"Yes_Stroke\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No_Heart Disease\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No_Physical Activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No_Fruits\",\"Eats_Fruits\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No_Veggies\",\"Eats_Veggies\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"Not_Heavy Drinker\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No_Health_Coverage\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"Cost_Issue\",\"Cost_Not_Issue\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num  18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num  15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No_Difficulty_Walking\",..: 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"None-K\",\"Grades 1-8\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"&lt;10K\",\"&lt;15K\",..: 3 1 8 6 4 8 7 4 1 3 ..."
  },
  {
    "objectID": "EDA.html#reading-in-data-and-converting-variables",
    "href": "EDA.html#reading-in-data-and-converting-variables",
    "title": "EDA",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyr)\n\ndata&lt;-read.csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\ndata&lt;- data|&gt;\n  mutate(HighBP=factor(HighBP, levels=c(0,1),labels=c(\"Normal_BP\",\"High_BP\")),\n         HighChol=factor(HighChol, levels=c(0,1),labels=c(\"Normal_Chol\",\"High_Chol\")),\n         CholCheck=as.factor(CholCheck),\n         Smoker=factor(Smoker,levels=c(0,1),labels=c(\"Non_Smoker\",\"Smoker\")),\n         Stroke=factor(Stroke, levels=c(0,1),labels=c(\"No_Stroke\",\"Yes_Stroke\")),\n         Fruits=factor(Fruits,levels=c(0,1),labels=c(\"No_Fruits\",\"Eats_Fruits\")),\n         Veggies=factor(Veggies,levels=c(0,1),labels=c(\"No_Veggies\",\"Eats_Veggies\")),\n         Sex=factor(Sex, level=c(0,1), labels = c(\"Female\",\"Male\")),\n         GenHlth=factor(GenHlth,levels=c(1,2,3,4,5), \n                        labels=c(\"Excellent\",\"Very Good\",\"Good\",\"Fair\",\"Poor\")),\n         Age=factor(Age, levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),\n                    labels=c(\"18-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"45-49\",\"50-54\",\"55-59\",\n                            \"60-64\",\"65-69\",\"70-74\",\"75-79\",\"80+\" )),\n         Education=factor(Education,levels=c(1,2,3,4,5,6),labels=c(\"None-K\",\"Grades 1-8\",\n                                                                   \"Grades 9-11\",\"HS Diploma\",\"Some College\",\"Bachelor's Degree or Higher\")),\n         Income=factor(Income,levels=c(1,2,3,4,5,6,7,8),labels=c(\"&lt;10K\",\"&lt;15K\",\n          \"&lt;20K\",\"&lt;25K\",\"&lt;35K\",\"&lt;50K\",\n          \"&lt;75K\",\"&gt;=75K\")),\n         Diabetes_binary=factor(Diabetes_binary,levels=c(0,1),labels=c(\"Not_Diabetic\",\"Diabetic\")),\n         HeartDiseaseorAttack=factor(HeartDiseaseorAttack,levels=c(0,1),labels=c(\"No_Heart Disease\",\"Heart_Disease\")),\n         PhysActivity=factor(PhysActivity,levels=c(0,1),labels=c(\"No_Physical Activity\",\"Physical_Activity\")),\n         HvyAlcoholConsump=factor(HvyAlcoholConsump,levels=c(0,1),labels=c(\"Not_Heavy Drinker\",\"Heavy_Drinker\")),\n         AnyHealthcare=factor(AnyHealthcare,levels=c(0,1),labels=c(\"No_Health_Coverage\",\"Yes_Health_Coverage\")),\n         NoDocbcCost=factor(NoDocbcCost,levels=c(0,1),labels=c(\"Cost_Issue\",\"Cost_Not_Issue\")),\n         DiffWalk=factor(DiffWalk,levels=c(0,1),labels=c(\"No_Difficulty_Walking\",\"Difficulty_Walking\"))\n         )\n\nstr(data)\n\n'data.frame':   253680 obs. of  22 variables:\n $ Diabetes_binary     : Factor w/ 2 levels \"Not_Diabetic\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"Normal_BP\",\"High_BP\": 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"Normal_Chol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : num  40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"Non_Smoker\",\"Smoker\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"No_Stroke\",\"Yes_Stroke\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No_Heart Disease\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"No_Physical Activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"No_Fruits\",\"Eats_Fruits\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"No_Veggies\",\"Eats_Veggies\": 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"Not_Heavy Drinker\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"No_Health_Coverage\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"Cost_Issue\",\"Cost_Not_Issue\": 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num  18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num  15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No_Difficulty_Walking\",..: 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"None-K\",\"Grades 1-8\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"&lt;10K\",\"&lt;15K\",..: 3 1 8 6 4 8 7 4 1 3 ..."
  },
  {
    "objectID": "EDA.html#basic-summaries-and-rates-of-missing",
    "href": "EDA.html#basic-summaries-and-rates-of-missing",
    "title": "EDA",
    "section": "Basic Summaries and Rates of Missing",
    "text": "Basic Summaries and Rates of Missing\n\nsum_na&lt;-function(column){\n  sum(is.na(column))\n}\n\nna_counts&lt;-data|&gt;\n  summarize(across(everything(),sum_na))\n\nprint(na_counts)\n\n  Diabetes_binary HighBP HighChol CholCheck BMI Smoker Stroke\n1               0      0        0         0   0      0      0\n  HeartDiseaseorAttack PhysActivity Fruits Veggies HvyAlcoholConsump\n1                    0            0      0       0                 0\n  AnyHealthcare NoDocbcCost GenHlth MentHlth PhysHlth DiffWalk Sex Age\n1             0           0       0        0        0        0   0   0\n  Education Income\n1         0      0\n\nsummaries&lt;- data|&gt;\n  summarize(across(where(is.numeric),\n                   list(\"mean\"=mean,\n                         \"median\"=median,\n                          \"min\"=min,\n                          \"max\"=max,\n                           \"sd\"=sd,\n                           \"iqr\"=IQR),\n                    .names=\"{.fn}_{.col}\"))\nprint(summaries)\n\n  mean_BMI median_BMI min_BMI max_BMI   sd_BMI iqr_BMI mean_MentHlth\n1 28.38236         27      12      98 6.608694       7      3.184772\n  median_MentHlth min_MentHlth max_MentHlth sd_MentHlth iqr_MentHlth\n1               0            0           30    7.412847            2\n  mean_PhysHlth median_PhysHlth min_PhysHlth max_PhysHlth sd_PhysHlth\n1      4.242081               0            0           30    8.717951\n  iqr_PhysHlth\n1            3\n\n\n\ntable(data$Sex,data$Diabetes_binary)\n\n        \n         Not_Diabetic Diabetic\n  Female       123563    18411\n  Male          94771    16935\n\ntable(data$Sex,data$Diabetes_binary,data$Age)\n\n, ,  = 18-24\n\n        \n         Not_Diabetic Diabetic\n  Female         2700       45\n  Male           2922       33\n\n, ,  = 25-29\n\n        \n         Not_Diabetic Diabetic\n  Female         3902       89\n  Male           3556       51\n\n, ,  = 30-34\n\n        \n         Not_Diabetic Diabetic\n  Female         5871      191\n  Male           4938      123\n\n, ,  = 35-39\n\n        \n         Not_Diabetic Diabetic\n  Female         7359      366\n  Male           5838      260\n\n, ,  = 40-44\n\n        \n         Not_Diabetic Diabetic\n  Female         8560      576\n  Male           6546      475\n\n, ,  = 45-49\n\n        \n         Not_Diabetic Diabetic\n  Female        10026      902\n  Male           8051      840\n\n, ,  = 50-54\n\n        \n         Not_Diabetic Diabetic\n  Female        13163     1642\n  Male          10063     1446\n\n, ,  = 55-59\n\n        \n         Not_Diabetic Diabetic\n  Female        15214     2255\n  Male          11355     2008\n\n, ,  = 60-64\n\n        \n         Not_Diabetic Diabetic\n  Female        15303     2968\n  Male          12208     2765\n\n, ,  = 65-69\n\n        \n         Not_Diabetic Diabetic\n  Female        14493     3250\n  Male          11143     3308\n\n, ,  = 70-74\n\n        \n         Not_Diabetic Diabetic\n  Female        10606     2553\n  Male           7786     2588\n\n, ,  = 75-79\n\n        \n         Not_Diabetic Diabetic\n  Female         7584     1834\n  Male           4993     1569\n\n, ,  = 80+\n\n        \n         Not_Diabetic Diabetic\n  Female         8782     1740\n  Male           5372     1469\n\ntable(data$Education,data$HighBP)\n\n                             \n                              Normal_BP High_BP\n  None-K                             86      88\n  Grades 1-8                       1654    2389\n  Grades 9-11                      3975    5503\n  HS Diploma                      31030   31720\n  Some College                    39019   30891\n  Bachelor's Degree or Higher     69087   38238\n\ntable(data$Education,data$HighChol)\n\n                             \n                              Normal_Chol High_Chol\n  None-K                               87        87\n  Grades 1-8                         1878      2165\n  Grades 9-11                        4741      4737\n  HS Diploma                        33789     28961\n  Some College                      40223     29687\n  Bachelor's Degree or Higher       65371     41954\n\ntable(data$Income)\n\n\n &lt;10K  &lt;15K  &lt;20K  &lt;25K  &lt;35K  &lt;50K  &lt;75K &gt;=75K \n 9811 11783 15994 20135 25883 36470 43219 90385 \n\ndata2&lt;-data|&gt;\n  filter( Income != \"&gt;=75K\" )\n\ntable(data2$Fruits,data2$Veggies,data2$Diabetes_binary)\n\n, ,  = Not_Diabetic\n\n             \n              No_Veggies Eats_Veggies\n  No_Fruits        18057        33201\n  Eats_Fruits      10772        73114\n\n, ,  = Diabetic\n\n             \n              No_Veggies Eats_Veggies\n  No_Fruits         4598         7293\n  Eats_Fruits       2899        13361\n\n\n\nggplot(data=data,aes(x=Sex,fill=Diabetes_binary))+\n  geom_bar(position=\"fill\")+\n  labs(x=\"Sex\")+\n  scale_fill_discrete(\"Diabetes Status\")\n\n\n\n\n\n\n\nggplot(data=data|&gt;group_by(Income),aes(x=Income,fill=Diabetes_binary))+\n  geom_bar(position=\"fill\")+\n  labs(x=\"Income\")+\n  scale_fill_discrete(\"Diabetes Status\")\n\n\n\n\n\n\n\n\n\n# Create a grouped boxplot using ggplot2\nggplot(data = data, aes(x = Education, y = BMI,\n                        fill = factor(Income))) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(fill = \"Income\")"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rpart)\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(baguette)\nlibrary(parsnip)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(lubridate)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nThe following objects are masked from 'package:scales':\n\n    alpha, rescale\n\nlibrary(tidymodels)\nlibrary(stats)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(tidyverse)\nlibrary(corrr)\nlibrary(parsnip)\nlibrary(tune)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(baguette)\nlibrary(ranger)\nlibrary(rpart.plot)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift"
  },
  {
    "objectID": "Modeling.html#libraries",
    "href": "Modeling.html#libraries",
    "title": "Modeling",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rpart)\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(baguette)\nlibrary(parsnip)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(lubridate)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nThe following objects are masked from 'package:scales':\n\n    alpha, rescale\n\nlibrary(tidymodels)\nlibrary(stats)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(tidyverse)\nlibrary(corrr)\nlibrary(parsnip)\nlibrary(tune)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(baguette)\nlibrary(ranger)\nlibrary(rpart.plot)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift"
  },
  {
    "objectID": "Modeling.html#setting-up-data",
    "href": "Modeling.html#setting-up-data",
    "title": "Modeling",
    "section": "Setting up Data",
    "text": "Setting up Data\n\ndata&lt;-read.csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\ndata&lt;- data|&gt;\n  mutate(HighBP=factor(HighBP, levels=c(0,1),labels=c(\"Normal_BP\",\"High_BP\")),\n         HighChol=factor(HighChol, levels=c(0,1),labels=c(\"Normal_Chol\",\"High_Chol\")),\n         CholCheck=as.factor(CholCheck),\n         Smoker=factor(Smoker,levels=c(0,1),labels=c(\"Non_Smoker\",\"Smoker\")),\n         Stroke=factor(Stroke, levels=c(0,1),labels=c(\"No_Stroke\",\"Yes_Stroke\")),\n         Fruits=factor(Fruits,levels=c(0,1),labels=c(\"No_Fruits\",\"Eats_Fruits\")),\n         Veggies=factor(Veggies,levels=c(0,1),labels=c(\"No_Veggies\",\"Eats_Veggies\")),\n         Sex=factor(Sex, level=c(0,1), labels = c(\"Female\",\"Male\")),\n         GenHlth=factor(GenHlth,levels=c(1,2,3,4,5), \n                        labels=c(\"Excellent\",\"Very Good\",\"Good\",\"Fair\",\"Poor\")),\n         Age=factor(Age, levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),\n                    labels=c(\"18-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"45-49\",\"50-54\",\"55-59\",\n                            \"60-64\",\"65-69\",\"70-74\",\"75-79\",\"80+\" )),\n         Education=factor(Education,levels=c(1,2,3,4,5,6),labels=c(\"None-K\",\"Grades 1-8\",\n                                                                   \"Grades 9-11\",\"HS Diploma\",\"Some College\",\"Bachelor's Degree or Higher\")),\n         Income=factor(Income,levels=c(1,2,3,4,5,6,7,8),labels=c(\"&lt;10K\",\"&lt;15K\",\n          \"&lt;20K\",\"&lt;25K\",\"&lt;35K\",\"&lt;50K\",\n          \"&lt;75K\",\"&gt;=75K\")),\n         Diabetes_binary=factor(Diabetes_binary,levels=c(0,1),labels=c(\"Not_Diabetic\",\"Diabetic\")),\n         HeartDiseaseorAttack=factor(HeartDiseaseorAttack,levels=c(0,1),labels=c(\"No_Heart Disease\",\"Heart_Disease\")),\n         PhysActivity=factor(PhysActivity,levels=c(0,1),labels=c(\"No_Physical Activity\",\"Physical_Activity\")),\n         HvyAlcoholConsump=factor(HvyAlcoholConsump,levels=c(0,1),labels=c(\"Not_Heavy Drinker\",\"Heavy_Drinker\")),\n         AnyHealthcare=factor(AnyHealthcare,levels=c(0,1),labels=c(\"No_Health_Coverage\",\"Yes_Health_Coverage\")),\n         NoDocbcCost=factor(NoDocbcCost,levels=c(0,1),labels=c(\"Cost_Issue\",\"Cost_Not_Issue\")),\n         DiffWalk=factor(DiffWalk,levels=c(0,1),labels=c(\"No_Difficulty_Walking\",\"Difficulty_Walking\"))\n         )\n\n\nset.seed(1234)\n\nsplit_data&lt;-initial_split(data,prop=0.1,strata = Diabetes_binary)\ntrain_data&lt;-training(split_data)\ntest_data&lt;-testing(split_data)\ncv_fold_data&lt;-vfold_cv(train_data,v=5,strata=Diabetes_binary)"
  },
  {
    "objectID": "Modeling.html#random-forest-model",
    "href": "Modeling.html#random-forest-model",
    "title": "Modeling",
    "section": "Random Forest Model",
    "text": "Random Forest Model\n\nrec1&lt;-recipe(Diabetes_binary~ Sex+Smoker+AnyHealthcare+GenHlth+PhysActivity,data=train_data)|&gt;\n   step_dummy(Sex,Smoker,GenHlth,AnyHealthcare,PhysActivity)\n\n\n\nrf_spec&lt;-rand_forest(mtry=tune())|&gt;\n  set_engine(\"ranger\")|&gt;\n  set_mode(\"classification\")\n\nrf_wkf&lt;-workflow()|&gt;\n  add_recipe(rec1)|&gt;\n  add_model(rf_spec)\n\nrf_fit&lt;-rf_wkf|&gt;\n  tune_grid(resamples=cv_fold_data,\n            grid=3,\n            metrics=metric_set(mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrf_fit|&gt;\n  collect_metrics()|&gt;\n  filter(.metric==\"mn_log_loss\")|&gt;\n  arrange(mean)\n\n# A tibble: 2 × 7\n   mtry .metric     .estimator  mean     n  std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1     3 mn_log_loss binary     0.360     5 0.000476 Preprocessor1_Model2\n2     7 mn_log_loss binary     0.360     5 0.000872 Preprocessor1_Model1\n\nrf_best_params&lt;-select_best(rf_fit,metric = \"mn_log_loss\")\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     3 Preprocessor1_Model2\n\nrf_final_wkf&lt;-rf_wkf|&gt;\n  finalize_workflow(rf_best_params)\n\nrf_final_fit&lt;-rf_final_wkf|&gt;\n  last_fit(split_data,metrics=metric_set(mn_log_loss))\n\nrf_final_fit|&gt;collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.359 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\n\ntree_mod&lt;-decision_tree(tree_depth = tune(),\n                        min_n = 5,\n                        cost_complexity = tune()\n                        )|&gt;\n  set_engine(\"rpart\")|&gt;\n  set_mode(\"classification\")\n\ntree_wkf&lt;-workflow()|&gt;\n  add_recipe(rec1)|&gt;\n  add_model(tree_mod)\n\ntemp&lt;-tree_wkf|&gt;\n  tune_grid(resamples = cv_fold_data,metrics = metric_set(mn_log_loss))\n  temp|&gt;\n    collect_metrics()\n\n# A tibble: 10 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1.29e-10         10 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 2        1.44e- 8          7 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 3        5.70e- 6          5 mn_log_loss binary     0.388     5 6.35e-3 Prepro…\n 4        1.12e- 6         15 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 5        9.18e- 3          5 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n 6        8.99e-10          8 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 7        8.44e- 8          2 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n 8        4.05e- 2         14 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n 9        2.10e- 4         11 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n10        2.92e- 5          3 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n\n  tree_grid&lt;-grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels=c(5,3))\n  tree_fits&lt;-tree_wkf|&gt;\n    tune_grid(resamples=cv_fold_data,metrics=metric_set(mn_log_loss),\n              grid=tree_grid)\n  \n  tree_fits\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits               id    .metrics          .notes          \n  &lt;list&gt;               &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [20293/5074]&gt; Fold1 &lt;tibble [15 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [20293/5074]&gt; Fold2 &lt;tibble [15 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [20293/5074]&gt; Fold3 &lt;tibble [15 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [20294/5073]&gt; Fold4 &lt;tibble [15 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [20295/5072]&gt; Fold5 &lt;tibble [15 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n  tree_fits|&gt;\n    collect_metrics()|&gt;\n    filter(.metric==\"mn_log_loss\")|&gt;\n    arrange(mean)\n\n# A tibble: 15 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          8 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 2    0.0000000178          8 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 3    0.00000316            8 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 4    0.0000000001         15 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 5    0.0000000178         15 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 6    0.00000316           15 mn_log_loss binary     0.378     5 5.38e-4 Prepro…\n 7    0.0000000001          1 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n 8    0.0000000178          1 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n 9    0.00000316            1 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n10    0.000562              1 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n11    0.1                   1 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n12    0.000562              8 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n13    0.1                   8 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n14    0.000562             15 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n15    0.1                  15 mn_log_loss binary     0.404     5 5.51e-5 Prepro…\n\ntree_best_params&lt;-select_best(tree_fits, metric=\"mn_log_loss\")\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          8 Preprocessor1_Model06\n\ntree_final_wkf&lt;-tree_wkf|&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit&lt;-tree_final_wkf|&gt;\n  last_fit(split_data,metrics=metric_set(mn_log_loss))\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [25367/228313]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ntree_final_fit|&gt;\n  collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.378 Preprocessor1_Model1\n\ntree_final_model&lt;-extract_workflow(tree_final_fit)\ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 25367 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 25367 3534 Not_Diabetic (0.86068514 0.13931486)  \n   2) GenHlth_Fair&lt; 0.5 22210 2562 Not_Diabetic (0.88464656 0.11535344)  \n     4) GenHlth_Poor&lt; 0.5 20927 2078 Not_Diabetic (0.90070244 0.09929756) *\n     5) GenHlth_Poor&gt;=0.5 1283  484 Not_Diabetic (0.62275916 0.37724084)  \n      10) Smoker_Smoker&gt;=0.5 822  291 Not_Diabetic (0.64598540 0.35401460) *\n      11) Smoker_Smoker&lt; 0.5 461  193 Not_Diabetic (0.58134490 0.41865510)  \n        22) AnyHealthcare_Yes_Health_Coverage&lt; 0.5 27   10 Not_Diabetic (0.62962963 0.37037037)  \n          44) Sex_Male&gt;=0.5 9    1 Not_Diabetic (0.88888889 0.11111111) *\n          45) Sex_Male&lt; 0.5 18    9 Not_Diabetic (0.50000000 0.50000000)  \n            90) PhysActivity_Physical_Activity&lt; 0.5 12    5 Not_Diabetic (0.58333333 0.41666667) *\n            91) PhysActivity_Physical_Activity&gt;=0.5 6    2 Diabetic (0.33333333 0.66666667) *\n        23) AnyHealthcare_Yes_Health_Coverage&gt;=0.5 434  183 Not_Diabetic (0.57834101 0.42165899) *\n   3) GenHlth_Fair&gt;=0.5 3157  972 Not_Diabetic (0.69211277 0.30788723) *\n\ntree_final_model %&gt;%\n  extract_fit_engine () %&gt;%\n  rpart.plot::rpart.plot(roundint=FALSE)"
  },
  {
    "objectID": "Modeling.html#final-and-best-model",
    "href": "Modeling.html#final-and-best-model",
    "title": "Modeling",
    "section": "Final and Best Model",
    "text": "Final and Best Model\n\nbest&lt;-rf_wkf|&gt;\n  finalize_workflow(rf_best_params)|&gt;\n  fit(data)\nbest\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~3L,      x), num.threads = 1, verbose = FALSE, seed = sample.int(10^5,      1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      253680 \nNumber of independent variables:  8 \nMtry:                             3 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1088137"
  }
]